# Evaluation: Signal Eventing, DAG Execution, and Streaming Support Proposals

**Evaluation Date:** January 30, 2026
**Evaluator:** Technical Review Team
**Source Document:** [signal_dag_streaming_proposal.md](signal_dag_streaming_proposal.md)

---

## Executive Summary

This document evaluates the three interconnected proposals for enhancing the Kindling framework. Overall assessment:

| Feature | Recommended Option | Risk Level | Priority | Readiness |
|---------|-------------------|------------|----------|-----------|
| **Signal Eventing** | Option C (Hybrid) | üü¢ Low | üî• High | ‚úÖ Ready |
| **DAG Execution** | Strategy Pattern | üü° Medium | üî• High | ‚úÖ Ready |
| **Streaming Support** | Comprehensive | üü° Medium | ‚ö° High | ‚ö†Ô∏è Needs refinement |
| **Dimension Restarts** | As proposed | üü† Medium-High | üìä Medium | ‚ö†Ô∏è Needs refinement |

**Overall Recommendation:** ‚úÖ **Proceed with phased implementation**, with modifications noted below.

---

## Part 1: Signal Eventing System Evaluation

### Option A: Simple Emit Pattern

**Strengths:**
- ‚úÖ Minimal disruption to existing codebase
- ‚úÖ Quick to implement (1-2 weeks)
- ‚úÖ Maintains backward compatibility
- ‚úÖ `EMITS` list provides basic documentation
- ‚úÖ Flexible for rapid iteration

**Weaknesses:**
- ‚ùå No compile-time safety (typos cause silent failures)
- ‚ùå `EMITS` list not enforced (can become stale)
- ‚ùå Payload structure not validated
- ‚ùå Limited IDE support (no autocomplete for signal names)
- ‚ùå Documentation must be manually maintained

**Technical Risks:**
- üü° Signal name typos won't be caught until runtime
- üü° Payload inconsistencies between emitter and subscriber
- üü¢ Low risk of breaking existing code

**Verdict:** ‚úÖ **Good for MVP/Phase 1**, but plan migration path to typed signals.

---

### Option B: Registry-Style Typed Signals

**Strengths:**
- ‚úÖ Type-safe payloads (IDE autocomplete, validation)
- ‚úÖ Self-documenting API
- ‚úÖ Can auto-generate documentation from registry
- ‚úÖ Catches errors at emit time
- ‚úÖ Refactoring-safe (rename signal ‚Üí update all usages)

**Weaknesses:**
- ‚ùå Significant boilerplate (dataclass per signal)
- ‚ùå Breaking change for dynamic signal patterns
- ‚ùå Overhead for simple signals
- ‚ùå Requires 3-4 weeks implementation
- ‚ùå May be overkill for low-frequency signals

**Technical Risks:**
- üü° Complexity may deter extension developers
- üü° Dataclass overhead for high-frequency signals
- üü† Migration from existing code could be disruptive

**Verdict:** ‚úÖ **Ideal for Phase 2+**, after patterns stabilize.

---

### Option C: Hybrid Approach (Recommended)

**Strengths:**
- ‚úÖ Best of both worlds: type-safe core, flexible extensions
- ‚úÖ Progressive enhancement path
- ‚úÖ Core framework gets safety, extensions get flexibility
- ‚úÖ Can migrate signals from string ‚Üí typed incrementally
- ‚úÖ Balances developer experience with safety

**Weaknesses:**
- ‚ö†Ô∏è Two patterns to learn (but clearly scoped)
- ‚ö†Ô∏è Requires discipline to decide when to use which
- ‚ö†Ô∏è Documentation must explain both patterns

**Technical Risks:**
- üü¢ Low risk: systems coexist naturally
- üü¢ Clear boundary: core = typed, extensions = flexible

**Implementation Considerations:**
- Start with simple emit pattern for all signals
- Migrate high-traffic signals (datapipes, entities) to typed in Phase 2
- Keep extension/plugin signals string-based

**Verdict:** ‚úÖ **RECOMMENDED** - Pragmatic balance with clear migration path.

---

### Async Signal Support Evaluation

**Proposal:** Wrap sync signals to schedule async handlers via `asyncio.create_task()`

**Strengths:**
- ‚úÖ Enables non-blocking signal handlers
- ‚úÖ Useful for streaming listeners (progress reporting, metrics)
- ‚úÖ Minimal changes to blinker integration
- ‚úÖ Event loop management isolated to async handlers

**Weaknesses:**
- ‚ö†Ô∏è Requires active event loop (not guaranteed in all contexts)
- ‚ö†Ô∏è Errors in async handlers don't propagate to emitter
- ‚ö†Ô∏è Debugging async failures more complex
- ‚ö†Ô∏è Spark environments don't have default event loop

**Critical Issues:**
1. **Event Loop Availability:** Spark driver doesn't run event loop by default
2. **Lifecycle Management:** Who starts/stops the loop? When?
3. **Error Handling:** Uncaught exceptions in async handlers silently fail

**Recommendations:**
- ‚úÖ Keep sync signals as default
- ‚úÖ Provide opt-in async wrapper for specific use cases
- ‚ö†Ô∏è Document event loop requirements clearly
- ‚ö†Ô∏è Provide error callback mechanism for async handlers
- ‚ö†Ô∏è Consider ThreadPoolExecutor as alternative to asyncio

**Modified Approach:**
```python
class SignalAsyncSupport:
    """Optional async support - use ThreadPoolExecutor as fallback."""

    def connect_async(self, signal_name: str, async_handler: Callable):
        if self._has_event_loop():
            # Use asyncio if available
            self._connect_with_asyncio(signal_name, async_handler)
        else:
            # Fallback to thread pool
            self._connect_with_threadpool(signal_name, async_handler)
```

**Verdict:** ‚úÖ **Useful but optional** - Implement in Phase 3, not critical path.

---

## Part 2: DAG Execution System Evaluation

### Strategy Pattern (Recommended)

**Strengths:**
- ‚úÖ Clean separation of concerns (strategy per execution mode)
- ‚úÖ Easy to add new strategies (e.g., priority-based, cost-optimized)
- ‚úÖ Testable in isolation
- ‚úÖ Follows established design patterns
- ‚úÖ Leverages NetworkX's proven topological algorithms

**Weaknesses:**
- ‚ö†Ô∏è NetworkX is not pre-installed on all platforms (Databricks)
- ‚ö†Ô∏è Fallback to graphlib provides sequential-only execution
- ‚ö†Ô∏è No parallel execution within generations in fallback mode

**Technical Evaluation:**

#### Batch vs Streaming Execution Order

**Batch (Forward Topo Sort):**
```
Generation 0: [producer_a, producer_b]  ‚Üí Run first
Generation 1: [transformer_c]           ‚Üí Run after producers
Generation 2: [consumer_d]              ‚Üí Run last
```
‚úÖ **Correct for batch:** Data flows naturally, dependencies satisfied.

**Streaming (Reverse Topo Sort):**
```
Generation 0: [consumer_d]              ‚Üí Start first (listening)
Generation 1: [transformer_c]           ‚Üí Start second (listening)
Generation 2: [producer_a, producer_b]  ‚Üí Start last (emitting)
```
‚úÖ **Correct for streaming:** Consumers ready before producers emit.

**Verdict:** ‚úÖ **CORRECT DESIGN** - Rationale is sound.

#### Cache Recommendations

**Proposal:** Identify entities consumed by multiple pipes ‚Üí recommend caching.

**Strengths:**
- ‚úÖ Automatic optimization without user intervention
- ‚úÖ Significant performance improvement for shared entities
- ‚úÖ Simple algorithm (count consumers per entity)

**Concerns:**
- ‚ö†Ô∏è Cache level (`MEMORY_AND_DISK`) may not suit all cases
- ‚ö†Ô∏è No consideration of entity size (small entities don't need caching)
- ‚ö†Ô∏è Cache eviction strategy not addressed

**Recommendations:**
- ‚úÖ Keep cache recommendations as advisory, not automatic
- ‚úÖ Add configuration to override cache level
- ‚úÖ Consider entity size in heuristic (e.g., only cache if > 100 MB)

#### Parallel Execution

**Proposal:** Use `ThreadPoolExecutor` to run pipes in parallel within generations.

**Critical Issue:** ‚ö†Ô∏è **Spark is not thread-safe for DataFrame operations!**

**Problems:**
1. Spark context is not thread-safe
2. Multiple threads creating DataFrames simultaneously can cause corruption
3. PySpark uses global state (SparkSession singleton)

**Correct Approach:**
```python
# ‚ùå WRONG - parallel DataFrame creation
with ThreadPoolExecutor(max_workers=4) as executor:
    futures = [executor.submit(pipe_executor, pipe_id) for pipe_id in generation]

# ‚úÖ CORRECT - parallel Python operations, sequential Spark operations
# OR use multiprocessing with separate Spark sessions
```

**Recommendations:**
- ‚ö†Ô∏è **Do NOT parallelize Spark DataFrame operations with threads**
- ‚úÖ Keep parallel execution for Python-only operations (file prep, etc.)
- ‚úÖ Consider process pool for true parallelism (overhead may not be worth it)
- ‚úÖ Document that parallelism is for planning, not execution (or limited scope)

**Modified Proposal:**
```python
class GenerationExecutor:
    def execute_generation(self, generation, pipe_executor):
        # For now, sequential execution within generation
        # Parallelism comes from Spark's distributed execution, not threads
        for pipe_id in generation:
            pipe_executor(pipe_id)

        # Future: Could use multiprocessing for independent Spark jobs
```

**Verdict:** ‚ö†Ô∏è **NEEDS MODIFICATION** - Remove thread-based parallelism or clarify scope.

---

### Configuration-Based Approach

**Strengths:**
- ‚úÖ User-friendly configuration object
- ‚úÖ Easy to adjust behavior without code changes

**Weaknesses:**
- ‚ö†Ô∏è Less extensible than strategy pattern
- ‚ö†Ô∏è Configuration object can become bloated

**Verdict:** ‚úÖ Use for user-facing API, strategy pattern for internal implementation.

---

## Part 3: Structured Streaming Support Evaluation

### Comprehensive Streaming Manager (Option A)

**Strengths:**
- ‚úÖ Complete feature set (lifecycle, monitoring, recovery)
- ‚úÖ Sync-based fits Spark's driver execution model
- ‚úÖ Signal-driven architecture for loose coupling
- ‚úÖ Configurable retry with exponential backoff

**Weaknesses:**
- ‚ö†Ô∏è Complex implementation (4-5 weeks)
- ‚ö†Ô∏è Thread-based monitoring adds complexity
- ‚ö†Ô∏è No integration with existing `SimplePipeStreamOrchestrator`

**Component Evaluation:**

#### StreamingQueryManager

**Strengths:**
- ‚úÖ Clean lifecycle management (register ‚Üí start ‚Üí stop)
- ‚úÖ Thread-safe with locks
- ‚úÖ Metrics tracking per query

**Concerns:**
- ‚ö†Ô∏è `query_builder` callable pattern may not fit all use cases
- ‚ö†Ô∏è No integration with existing pipe metadata
- ‚ö†Ô∏è Metrics don't capture Spark's native query metrics

**Recommendations:**
- ‚úÖ Extend `PipeMetadata` to include streaming config
- ‚úÖ Bridge to Spark's `StreamingQuery.status` for metrics
- ‚úÖ Support both builder callable and direct `StreamingQuery` registration

#### StreamingWatchdog

**Strengths:**
- ‚úÖ Separate thread for non-blocking monitoring
- ‚úÖ Configurable health check interval
- ‚úÖ Stale query detection

**Concerns:**
- ‚ö†Ô∏è Polling-based (not event-driven)
- ‚ö†Ô∏è No coordination with Spark's `StreamingQueryListener`
- ‚ö†Ô∏è Duplicate monitoring (watchdog + listener)

**Recommendations:**
- ‚úÖ Use `StreamingQueryListener` as primary source
- ‚úÖ Watchdog as backup for listener failures
- ‚úÖ Reduce polling frequency (watchdog as safety net, not primary)

#### StreamingRecoveryManager

**Strengths:**
- ‚úÖ Exponential backoff is industry standard
- ‚úÖ Max retry limit prevents infinite loops
- ‚úÖ Separate thread for non-blocking recovery

**Concerns:**
- ‚ö†Ô∏è No distinction between transient vs permanent failures
- ‚ö†Ô∏è Recovery always restarts from checkpoint (may not be desired)
- ‚ö†Ô∏è No alert mechanism when max retries exhausted

**Recommendations:**
- ‚úÖ Add failure classification (transient, permanent, unknown)
- ‚úÖ Support custom recovery strategies (not just restart)
- ‚úÖ Emit `recovery_exhausted` signal for human intervention

#### KindlingStreamingListener

**Strengths:**
- ‚úÖ Bridges Spark events to Kindling signals
- ‚úÖ Captures progress, termination events
- ‚úÖ Non-blocking recovery trigger

**Concerns:**
- ‚ö†Ô∏è Listener callbacks run on Spark's listener thread (blocking concerns)
- ‚ö†Ô∏è Spawning threads from listener may cause issues
- ‚ö†Ô∏è Exception in listener can crash all streaming queries

**Critical Issue:** Spark's `StreamingQueryListener` callbacks must not block!

**Recommendations:**
- ‚úÖ Make callbacks extremely lightweight (queue event, return immediately)
- ‚úÖ Process events in separate thread (queue ‚Üí processor pattern)
- ‚úÖ Add exception handling around all listener methods

**Modified Approach:**
```python
class KindlingStreamingListener(StreamingQueryListener):
    def __init__(self, ...):
        self._event_queue = queue.Queue()
        self._processor_thread = threading.Thread(target=self._process_events)
        self._processor_thread.start()

    def onQueryProgress(self, event):
        # Non-blocking: queue and return
        self._event_queue.put(('progress', event))

    def _process_events(self):
        # Process queued events in background thread
        while True:
            event_type, event = self._event_queue.get()
            try:
                self._handle_event(event_type, event)
            except Exception as e:
                logger.error(f"Error processing event: {e}")
```

**Verdict:** ‚ö†Ô∏è **NEEDS REFINEMENT** - Add queue-based processing, better error handling.

---

### Event Loop-Based Async Monitoring (Option B)

**Strengths:**
- ‚úÖ Modern async patterns
- ‚úÖ Efficient for high-frequency monitoring

**Weaknesses:**
- ‚ùå Event loop not guaranteed in Spark driver
- ‚ùå More complex than sync approach
- ‚ùå Doesn't fit Spark's execution model

**Verdict:** ‚ùå **NOT RECOMMENDED** - Sync approach is more appropriate for Spark.

---

## Part 4: Dimension-Driven Stream Restart Evaluation

### Overall Concept

**Strengths:**
- ‚úÖ Solves real pain point (stale dimension data in streams)
- ‚úÖ Signal-driven architecture fits framework design
- ‚úÖ Graceful restart preserves checkpoints
- ‚úÖ Cascading restarts handle dependencies

**Weaknesses:**
- ‚ö†Ô∏è Complex feature with many edge cases
- ‚ö†Ô∏è Restart downtime means data loss (streaming gap)
- ‚ö†Ô∏è Dimension version polling adds overhead

**Alternative Approaches:**
1. **Streaming dimension table** - Use Delta's change data feed
2. **Periodic refresh** - Restart on schedule, not on change
3. **Dual-stream join** - Join with dimension stream (complex but no downtime)

**Recommendation:** ‚úÖ Proceed, but provide alternatives in documentation.

---

### DimensionChangeDetector

**Strengths:**
- ‚úÖ Simple version polling approach
- ‚úÖ Watches multiple dimensions efficiently
- ‚úÖ Configurable check interval

**Concerns:**
- ‚ö†Ô∏è Polling every dimension every 60s could be expensive
- ‚ö†Ô∏è No batching of version checks
- ‚ö†Ô∏è Delta's `get_entity_version()` may not be cheap
- ‚ö†Ô∏è No consideration of dimension size (small changes don't need restart)

**Recommendations:**
- ‚úÖ Batch version checks (single query for all dimensions)
- ‚úÖ Add minimum change threshold (version delta > N)
- ‚úÖ Consider Delta change data feed as alternative to polling
- ‚úÖ Support user-defined change detection (not just version)

**Modified Approach:**
```python
class DimensionChangeDetector:
    def _check_all_dimensions(self):
        """Batch check all dimensions in single query."""
        dimension_ids = list(self._watched_dimensions.keys())

        # Batch query for all versions
        versions = self.entity_provider.get_versions_batch(dimension_ids)

        for entity_id, current_version in versions.items():
            last_version = self._watched_dimensions[entity_id]
            if current_version > last_version:
                self._handle_dimension_change(entity_id, last_version, current_version)
```

---

### StreamRestartController

**Strengths:**
- ‚úÖ Signal-driven restart coordination
- ‚úÖ Graceful shutdown ‚Üí update ‚Üí restart sequence
- ‚úÖ Background thread prevents blocking
- ‚úÖ Tracks dependencies per query

**Concerns:**
- ‚ö†Ô∏è No coordination between multiple restarts (race conditions)
- ‚ö†Ô∏è Restart sequence doesn't verify checkpoint validity
- ‚ö†Ô∏è No pre-restart validation (dimension might not be ready)
- ‚ö†Ô∏è Restart always stops query (no zero-downtime option)

**Critical Issues:**

1. **Checkpoint Compatibility:** After dimension schema change, checkpoint may be invalid
2. **Restart Storms:** Multiple dimensions changing ‚Üí many queries restarting
3. **Resource Contention:** Multiple queries restarting simultaneously

**Recommendations:**
- ‚úÖ Add restart throttling (max N concurrent restarts)
- ‚úÖ Validate checkpoint before restart (or offer clean start option)
- ‚úÖ Add restart coordination (queue restarts, execute serially)
- ‚úÖ Support "preview" mode (validate dimension before commit to restart)

**Modified Approach:**
```python
class StreamRestartController:
    def __init__(self, ...):
        self._restart_queue = queue.Queue()
        self._restart_semaphore = threading.Semaphore(max_concurrent_restarts)
        self._restart_processor = threading.Thread(target=self._process_restarts)

    def _schedule_restart(self, query_id, reason, **context):
        # Queue restart instead of immediate execution
        self._restart_queue.put((query_id, reason, context))

    def _process_restarts(self):
        # Process restart queue with concurrency control
        while True:
            query_id, reason, context = self._restart_queue.get()
            with self._restart_semaphore:
                self._execute_restart(query_id, reason, context)
```

---

### Cascading Restarts

**Strengths:**
- ‚úÖ Handles multi-level dependencies
- ‚úÖ Reverse order (consumers first) is correct for streaming

**Concerns:**
- ‚ö†Ô∏è Graph traversal may be expensive for large DAGs
- ‚ö†Ô∏è No cycle detection (could infinite loop)
- ‚ö†Ô∏è All-or-nothing restart (no partial restart option)

**Recommendations:**
- ‚úÖ Add cycle detection (use NetworkX's `is_directed_acyclic_graph`)
- ‚úÖ Support depth limit for cascading (don't restart entire graph)
- ‚úÖ Add dry-run mode (preview affected queries without restarting)

---

## Integration & Cross-Cutting Concerns

### Signal Consistency

**Issue:** Same events emitted from multiple places with different names.

**Example:**
- `datapipes.before_run` vs `execution.before_generation` vs `streaming.before_start`

**Recommendation:**
- ‚úÖ Establish namespace hierarchy: `{component}.{action}.{phase}`
- ‚úÖ Document naming conventions in [signal_quick_reference.md](../signal_quick_reference.md)
- ‚úÖ Validate consistency in tests

### Performance Impact

**Signals:**
- üü¢ Low overhead (blinker is fast)
- üü° Many subscribers can add latency
- ‚úÖ Recommendation: Keep critical path signals minimal

**DAG Construction:**
- üü° Graph build is O(pipes * dependencies)
- üü° Topological sort is O(V + E)
- ‚úÖ Recommendation: Cache execution plans

**Dimension Polling:**
- üü† Checking N dimensions every 60s can be expensive
- ‚úÖ Recommendation: Batch checks, increase interval

### Error Handling

**Current Gaps:**
- ‚ö†Ô∏è No central error handling strategy
- ‚ö†Ô∏è Async handlers silently fail
- ‚ö†Ô∏è Recovery exhaustion not clearly handled

**Recommendations:**
- ‚úÖ Add `ErrorHandler` interface for pluggable error handling
- ‚úÖ Default handler logs errors and emits signals
- ‚úÖ Support custom handlers for alerts, retries, etc.

### Testing Strategy

**Required Test Coverage:**

| Component | Unit Tests | Integration Tests | System Tests |
|-----------|-----------|-------------------|--------------|
| Signals | ‚úÖ High | ‚úÖ Medium | üü° Low |
| DAG Execution | ‚úÖ High | ‚úÖ High | ‚úÖ High |
| Streaming | ‚úÖ High | ‚úÖ High | ‚úÖ Critical |
| Dimension Restart | ‚úÖ Medium | ‚úÖ High | ‚úÖ Critical |

**Specific Tests Needed:**
1. Signal ordering (before/after sequences)
2. DAG cycle detection
3. Parallel execution safety (thread-safety)
4. Streaming restart race conditions
5. Dimension change during restart
6. Checkpoint recovery after schema change

---

## Risk Assessment

### High Risks üî¥

1. **Parallel Execution Thread Safety**
   - **Issue:** Spark DataFrames not thread-safe
   - **Mitigation:** Remove thread-based parallelism or scope to non-Spark operations
   - **Status:** ‚ö†Ô∏è Requires design change

2. **StreamingQueryListener Blocking**
   - **Issue:** Listener callbacks must not block
   - **Mitigation:** Queue-based event processing
   - **Status:** ‚ö†Ô∏è Requires implementation change

3. **Checkpoint Compatibility After Restart**
   - **Issue:** Dimension schema changes may invalidate checkpoints
   - **Mitigation:** Validate checkpoints, offer clean start option
   - **Status:** ‚ö†Ô∏è Needs additional design

### Medium Risks üü°

4. **NetworkX Dependency**
   - **Issue:** Not pre-installed on all platforms
   - **Mitigation:** Fallback to graphlib (sequential only)
   - **Status:** ‚úÖ Acceptable tradeoff

5. **Restart Storms**
   - **Issue:** Many dimensions changing ‚Üí many restarts
   - **Mitigation:** Restart throttling, queuing
   - **Status:** ‚ö†Ô∏è Needs implementation

6. **Event Loop Management**
   - **Issue:** Spark doesn't provide default event loop
   - **Mitigation:** Make async support optional, document requirements
   - **Status:** ‚úÖ Addressed in recommendations

### Low Risks üü¢

7. **Signal Overhead**
   - **Issue:** Many signals may impact performance
   - **Mitigation:** Signals are opt-in via subscription
   - **Status:** ‚úÖ Not a concern

8. **Configuration Complexity**
   - **Issue:** Many config options to manage
   - **Mitigation:** Sensible defaults, good documentation
   - **Status:** ‚úÖ Manageable

---

## Recommendations Summary

### Immediate Actions (Before Implementation)

1. ‚ö†Ô∏è **Remove thread-based parallel execution** or clarify it's for planning only
2. ‚ö†Ô∏è **Refactor StreamingQueryListener** to use queue-based processing
3. ‚ö†Ô∏è **Add restart throttling** to StreamRestartController
4. ‚ö†Ô∏è **Add checkpoint validation** before stream restarts
5. ‚úÖ **Document async signal requirements** clearly

### Phase 1: Signal Enhancements (Proceed)

- ‚úÖ Implement Option C (Hybrid approach)
- ‚úÖ Start with simple emit pattern for all signals
- ‚úÖ Document migration path to typed signals
- ‚úÖ Skip async support for now (Phase 3)

### Phase 2: DAG Execution (Proceed with modifications)

- ‚úÖ Implement strategy pattern as proposed
- ‚ö†Ô∏è Remove/clarify parallel execution within generations
- ‚úÖ Keep cache recommendations advisory (not automatic)
- ‚úÖ Add execution plan caching

### Phase 3: Streaming Support (Proceed with refinements)

- ‚úÖ Implement comprehensive manager approach
- ‚ö†Ô∏è Add queue-based listener processing
- ‚ö†Ô∏è Add restart throttling and coordination
- ‚úÖ Integrate with existing `SimplePipeStreamOrchestrator`

### Phase 4: Dimension Restarts (Defer or refine)

- ‚ö†Ô∏è **Consider deferring to Phase 4** (not critical path)
- ‚úÖ Add batch version checking
- ‚úÖ Add checkpoint validation
- ‚úÖ Document alternative approaches (streaming dimensions, scheduled restarts)
- ‚úÖ Add dry-run mode for testing

---

## Revised Timeline Estimate

| Phase | Original | Revised | Change Reason |
|-------|----------|---------|---------------|
| Signal Enhancements | 2-3 weeks | 2-3 weeks | ‚úÖ No change |
| DAG Execution | 3-4 weeks | 4-5 weeks | Modified parallel execution design |
| Streaming Support | 4-5 weeks | 5-6 weeks | Queue-based listener, restart coordination |
| Dimension Restarts | (included) | 3-4 weeks | New phase, additional features |
| Integration & Polish | 2-3 weeks | 3-4 weeks | More testing needed |
| **Total** | **11-15 weeks** | **17-22 weeks** | More realistic for production quality |

---

## Final Verdict

### Overall Assessment: ‚úÖ **APPROVE WITH MODIFICATIONS**

The proposals demonstrate excellent architectural thinking and address real pain points in data engineering workflows. Key strengths:

- ‚úÖ Signal-based architecture enables loose coupling
- ‚úÖ DAG execution is a major improvement over sequential
- ‚úÖ Streaming support fills a critical gap
- ‚úÖ Dimension restart solves a real problem

**However, critical issues must be addressed:**

1. Thread-safety concerns with parallel execution
2. StreamingQueryListener blocking concerns
3. Checkpoint compatibility after restarts
4. Overall complexity and timeline

**Recommended Approach:**

1. **Proceed with Phases 1-2** (Signals + DAG) - Lower risk, high value
2. **Refine Phase 3** (Streaming) - Address listener and restart concerns
3. **Consider Phase 4** (Dimension restarts) - High value but can be deferred

The proposals are well-thought-out and technically sound with the modifications noted. Implementing these features will significantly enhance Kindling's capabilities and competitive positioning in the data lakehouse orchestration space.

---

## Appendix: Alternative Considerations

### Alternative to Dimension Polling: Delta Change Data Feed

Instead of polling version numbers:

```python
# Subscribe to Delta CDF for dimension changes
dim_changes = spark.readStream \
    .format("delta") \
    .option("readChangeFeed", "true") \
    .option("startingVersion", last_version) \
    .load("/data/silver/customers")

# Trigger restart on any change
dim_changes.writeStream \
    .foreachBatch(lambda batch, id: restart_controller.request_restart("my_query")) \
    .start()
```

**Pros:** Real-time, no polling overhead, leverages Spark's streaming
**Cons:** Requires separate streaming query per dimension, more complex

**Recommendation:** Offer both approaches, let users choose.

---

### Alternative to Parallel Execution: Process Pool

For true parallelism without thread-safety issues:

```python
from multiprocessing import Pool

def execute_pipe_in_process(pipe_id):
    # Each process gets its own Spark session
    spark = SparkSession.builder.getOrCreate()
    # Execute pipe...

with Pool(processes=4) as pool:
    pool.map(execute_pipe_in_process, generation)
```

**Pros:** True parallelism, no thread-safety issues
**Cons:** Overhead of spawning processes, serialization costs

**Recommendation:** Document as advanced option, not default.
