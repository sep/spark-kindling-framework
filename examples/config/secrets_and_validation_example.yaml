# ============================================================================
# Kindling Framework Configuration Example
# Secret References & Validation
# ============================================================================
#
# This example demonstrates:
# 1. Secret references with @secret syntax
# 2. Variable interpolation with @format
# 3. Configuration validation with Dynaconf validators
# 4. Platform-specific secret overrides
# 5. Environment-specific secret patterns
#
# Dynaconf Features Used:
# - @secret: JIT secret retrieval via custom loader
# - @format {this.path.to.key}: Reference other config values
# - Validators: Ensure required secrets exist and meet conditions
# - Hierarchical overrides: Platform/workspace/environment layers
#
# ============================================================================

# Base Configuration (all platforms/environments)
kindling:

  # Application metadata
  version: "2.0.0"
  app_name: "data-lakehouse"

  # ========================================================================
  # Storage Configuration with Interpolation
  # ========================================================================
  storage:
    account: "mydatalake"
    container: "analytics"

    # Interpolated base path using account and container
    base_path: "@format abfss://{this.kindling.storage.container}@{this.kindling.storage.account}.dfs.core.windows.net"

    # Layer paths derived from base path
    bronze_path: "@format {this.kindling.storage.base_path}/bronze"
    silver_path: "@format {this.kindling.storage.base_path}/silver"
    gold_path: "@format {this.kindling.storage.base_path}/gold"

    # Secret reference for storage access key
    # Resolved via platform-specific SecretProvider (KeyVault/DbSecrets/EnvVars)
    access_key: "@secret storage-account-key"

  # ========================================================================
  # Snowflake External Provider with Secrets
  # ========================================================================
  snowflake:
    account: "mycompany"
    region: "us-east-1"
    database: "analytics_db"
    schema: "public"
    warehouse: "compute_wh"
    role: "DATA_ENGINEER"

    # Interpolated connection string
    connection_string: "@format {this.kindling.snowflake.account}.{this.kindling.snowflake.region}.snowflakecomputing.com"

    # Secrets resolved via platform-specific provider
    username: "@secret snowflake-username"
    password: "@secret snowflake-password"

    # Connection settings
    timeout_seconds: 30
    retry_count: 3
    autocommit: false

  # ========================================================================
  # External REST API Configuration
  # ========================================================================
  external_api:
    base_url: "https://api.example.com"
    version: "v2"

    # Interpolated full endpoint URL
    endpoint: "@format {this.kindling.external_api.base_url}/{this.kindling.external_api.version}"

    # Secret embedded in Authorization header using @format + @secret
    auth_header: "@format Bearer {@secret api-token}"

    # API settings
    timeout_seconds: 60
    max_retries: 3
    rate_limit_per_minute: 100

  # ========================================================================
  # Database Connection (PostgreSQL example)
  # ========================================================================
  postgres:
    host: "postgres.example.com"
    port: 5432
    database: "analytics"

    # Secrets for credentials
    username: "@secret postgres-username"
    password: "@secret postgres-password"

    # Interpolated connection URL with embedded secrets
    # Note: @format resolves @secret references automatically
    connection_url: "@format postgresql://{@secret postgres-username}:{@secret postgres-password}@{this.kindling.postgres.host}:{this.kindling.postgres.port}/{this.kindling.postgres.database}"

    # Connection pool settings
    pool_size: 10
    max_overflow: 20

  # ========================================================================
  # Entity Provider Configuration
  # ========================================================================
  entity_providers:

    # Delta Lake provider (default)
    delta:
      provider_type: "delta"
      # Path pattern with layer interpolation
      path_pattern: "@format {this.kindling.storage.{layer}_path}/{entity_name}"
      merge_schema: true
      optimize_on_write: true

    # Snowflake external provider
    snowflake:
      provider_type: "snowflake"
      enabled: true
      # References snowflake config defined above
      connection_config: "@format {this.kindling.snowflake}"
      # Table naming convention
      table_pattern: "@format {this.kindling.snowflake.schema}.{entity_name}"

    # CSV file provider
    csv:
      provider_type: "csv"
      base_path: "@format {this.kindling.storage.bronze_path}/csv"
      # Pattern for CSV files
      file_pattern: "@format {this.kindling.entity_providers.csv.base_path}/{entity_name}.csv"
      encoding: "utf-8"
      delimiter: ","
      header: true

  # ========================================================================
  # Telemetry & Monitoring
  # ========================================================================
  telemetry:
    enabled: true

    # Application Insights (Azure)
    app_insights:
      enabled: true
      # Secret reference for instrumentation key
      instrumentation_key: "@secret app-insights-key"
      connection_string: "@format InstrumentationKey={@secret app-insights-key};IngestionEndpoint=https://westus2-2.in.applicationinsights.azure.com/"

    # Custom metrics endpoint
    metrics_endpoint:
      url: "https://metrics.example.com/api/v1/metrics"
      # API key secret
      api_key: "@secret metrics-api-key"
      # Full auth header
      auth_header: "@format X-API-Key: {@secret metrics-api-key}"

    # Logging configuration
    logging:
      level: "INFO"
      structured: true
      # Log storage with secret
      log_storage_path: "@format {this.kindling.storage.base_path}/logs"
      log_storage_key: "@secret log-storage-key"

  # ========================================================================
  # Secret Provider Configuration (platform-specific)
  # ========================================================================
  secrets:
    # This section configures SecretProvider behavior
    # Platform-specific implementations will override these
    cache_ttl_seconds: 300  # 5 minutes
    retry_count: 3
    retry_delay_seconds: 1

# ============================================================================
# Platform-Specific Overrides
# ============================================================================
# NOTE: The sections below are examples of separate YAML files.
# In production, these would be in separate files:
# - platform_fabric.yaml
# - platform_databricks.yaml
# - platform_synapse.yaml
# - env_dev.yaml
# - env_prod.yaml
# ============================================================================

# ============================================================================
# EXAMPLE FILE: platform_fabric.yaml
# ============================================================================
# Platform: Fabric
# These settings override base config when running on Fabric
fabric:
  kindling:
    # Fabric uses OneLake paths
    storage:
      base_path: "Files"
      bronze_path: "Files/bronze"
      silver_path: "Files/silver"
      gold_path: "Files/gold"
      # Key Vault reference pattern (Fabric-specific)
      access_key: "@secret storage-account-key"  # Resolved via Azure Key Vault

    # Fabric secret provider config
    secrets:
      provider_type: "azure_keyvault"
      # Key Vault URL for Fabric workspace
      key_vault_url: "https://my-fabric-vault.vault.azure.net"
      # Uses mssparkutils.credentials.getSecret()
      use_mssparkutils: true

# ============================================================================
# EXAMPLE FILE: platform_databricks.yaml
# ============================================================================
# Platform: Databricks
databricks:
  kindling:
    # Databricks uses DBFS or Unity Catalog paths
    storage:
      base_path: "/mnt/datalake"
      bronze_path: "/mnt/datalake/bronze"
      silver_path: "/mnt/datalake/silver"
      gold_path: "/mnt/datalake/gold"
      # Databricks Secrets reference pattern
      access_key: "@secret storage-account-key"  # Resolved via Databricks Secrets

    # Databricks secret provider config
    secrets:
      provider_type: "databricks_secrets"
      # Databricks secret scope name
      secret_scope: "production-secrets"
      # Uses dbutils.secrets.get()
      use_dbutils: true

# ============================================================================
# EXAMPLE FILE: platform_synapse.yaml
# ============================================================================
# Platform: Synapse
synapse:
  kindling:
    # Synapse uses ADLS Gen2 paths
    storage:
      account: "mysynapsedatalake"
      container: "data"
      base_path: "@format abfss://{this.kindling.storage.container}@{this.kindling.storage.account}.dfs.core.windows.net"
      bronze_path: "@format {this.kindling.storage.base_path}/bronze"
      silver_path: "@format {this.kindling.storage.base_path}/silver"
      gold_path: "@format {this.kindling.storage.base_path}/gold"
      # Key Vault reference pattern (Synapse-specific)
      access_key: "@secret storage-account-key"  # Resolved via Azure Key Vault

    # Synapse secret provider config (uses Key Vault like Fabric)
    secrets:
      provider_type: "azure_keyvault"
      key_vault_url: "https://my-synapse-vault.vault.azure.net"
      use_mssparkutils: true

# ============================================================================
# EXAMPLE FILE: env_dev.yaml
# ============================================================================
# Environment: Development
development:
  kindling:
    # Dev uses local storage
    storage:
      base_path: "./local_data"
      bronze_path: "./local_data/bronze"
      silver_path: "./local_data/silver"
      gold_path: "./local_data/gold"
      # Dev secrets from environment variables
      access_key: "@secret DEV_STORAGE_KEY"

    # Dev uses environment variable secret provider
    secrets:
      provider_type: "environment_variables"
      secret_prefix: "DEV_"  # Secrets loaded from DEV_* env vars
      required_env_vars:
        - "DEV_STORAGE_KEY"
        - "DEV_SNOWFLAKE_PASSWORD"
        - "DEV_API_TOKEN"

    # Dev overrides for external services
    snowflake:
      account: "mycompany_dev"
      database: "analytics_dev"
      username: "@secret DEV_SNOWFLAKE_USERNAME"
      password: "@secret DEV_SNOWFLAKE_PASSWORD"

    # Dev telemetry disabled or uses different endpoint
    telemetry:
      enabled: false

# ============================================================================
# EXAMPLE FILE: env_prod.yaml
# ============================================================================
# Environment: Production
production:
  kindling:
    # Production storage config (uses platform defaults)
    # Secrets remain as-is, resolved via platform-specific provider

    # Production secrets config
    secrets:
      # Shorter cache TTL for production (more frequent refresh)
      cache_ttl_seconds: 60
      retry_count: 5

    # Production telemetry (must be enabled)
    telemetry:
      enabled: true
      logging:
        level: "WARN"  # Less verbose in production
