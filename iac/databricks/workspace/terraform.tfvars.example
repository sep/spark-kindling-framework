# =============================================================================
# Databricks Workspace Terraform Variables
# =============================================================================
# Copy this file to <env>.tfvars and fill in your values.
# .tfvars files are gitignored â€” do NOT commit real values.
#
# Usage:
#   terraform plan  -var-file=dev.tfvars
#   terraform apply -var-file=dev.tfvars
# =============================================================================

# -- Azure --------------------------------------------------------------------
azure_subscription_id = ""  # Your Azure subscription ID
azure_tenant_id       = ""  # Your Azure AD tenant ID
azure_environment     = "public" # Set to "usgovernment" for Azure US Gov

# -- Databricks Workspace ----------------------------------------------------
databricks_host = ""        # e.g. "https://adb-1234567890.1.azuredatabricks.net"
environment     = "dev"
enable_unity_catalog = true # Set false for non-UC workspaces (skips UC resources and grants)

# -- Data Lake ----------------------------------------------------------------
datalake_storage_account = ""  # ADLS Gen2 storage account name
adls_dfs_domain          = "dfs.core.windows.net" # Use dfs.core.usgovcloudapi.net for Azure US Gov
artifacts_container_name = "artifacts"
artifacts_external_location_name = "artifacts"

storage_credential_auth_type = "access_connector" # access_connector or service_principal
storage_credential_sp_application_id = null       # required for service_principal mode
storage_credential_sp_client_secret  = null       # required for service_principal mode
storage_credential_sp_directory_id   = null       # optional; defaults to azure_tenant_id

# Full resource ID of the Databricks access connector with managed identity
# that has Storage Blob Data Contributor on the storage account
access_connector_id = ""  # Required when create_access_connector=false
create_access_connector = false
access_connector_name = "kindling-access-connector" # Used when create_access_connector=true
access_connector_resource_group_name = ""            # Required when create_access_connector=true
access_connector_location = ""                       # Required when create_access_connector=true
datalake_storage_account_resource_group_name = ""    # Required for RBAC lookup unless datalake_storage_account_id is set
datalake_storage_account_id = null                   # Optional direct RBAC scope

storage_credential_name = "datalake_managed_identity"

# -- Unity Catalog ------------------------------------------------------------
catalog_name              = "medallion"
create_catalog            = true  # false to use an existing catalog_name
create_base_schemas       = true  # false to skip creating var.schemas (for existing catalogs)
catalog_storage_container = "artifacts"  # Container for catalog managed storage
catalog_storage_path      = "catalog"    # Path within container
kindling_catalog_name = "kindling"
create_kindling_catalog = true
kindling_catalog_storage_container = "artifacts"
kindling_catalog_storage_path = "kindling/catalog"
kindling_schema_name = "kindling"
kindling_artifacts_volume_name = "artifacts"
kindling_artifacts_subpath = "kindling/artifacts"

schemas = [
  # { name = "bronze", storage_root = null },
  # { name = "silver", storage_root = "abfss://silver@mystorageaccount.dfs.core.windows.net/" },
]

managed_volumes = []

# -- Secret Scopes ------------------------------------------------------------
secret_scopes = []  # e.g. ["my-secret-scope"]

# -- Service Principals -------------------------------------------------------
service_principals = [
  # { display_name = "my-sp", application_id = "00000000-0000-0000-0000-000000000000" },
]
create_runtime_service_principal     = false
runtime_service_principal_display_name = "kindling-runtime"
runtime_service_principal_application_id = null
runtime_sp_principal_alias           = "TODO_RUNTIME_SP_APP_ID"

# -- Users & Groups -----------------------------------------------------------
admin_users = [
  # "admin@example.com",
]

workspace_users = [
  # "user1@example.com",
  # "user2@example.com",
]
manage_system_group_memberships = true

# -- Clusters -----------------------------------------------------------------
clusters = [
  # {
  #   name                    = "My Cluster"
  #   spark_version           = "13.3.x-scala2.12"
  #   node_type_id            = "Standard_DS3_v2"
  #   num_workers             = 0          # 0 = single node
  #   autotermination_minutes = 60
  #   data_security_mode      = "USER_ISOLATION"
  #   spot_policy             = "SPOT_WITH_FALLBACK_AZURE"
  # },
]

# -- DLT Pipelines -----------------------------------------------------------
# NOTE: These depend on notebooks being present in the workspace first.
dlt_pipelines = [
  # {
  #   name          = "ingestion_pipeline"
  #   target_schema = "bronze"
  #   notebook_path = "/my-org/run_ingestion_dlts"
  #   development   = true
  # },
]

# -- Workspace Config ---------------------------------------------------------
workspace_conf = {
  # enableDbfsFileBrowser = "true"
}

# -- Unity Catalog Grants ----------------------------------------------------
# Grant privileges on the catalog to specific principals (SPs, groups, etc.)
catalog_grants = [
  # { principal = "my-sp-app-id",   privileges = ["USE_CATALOG", "USE_SCHEMA", "SELECT"] },
  # { principal = "account users",  privileges = ["BROWSE"] },
]

kindling_catalog_grants = [
  # { principal = "my-sp-app-id",   privileges = ["USE_CATALOG", "USE_SCHEMA", "SELECT"] },
  # { principal = "account users",  privileges = ["BROWSE"] },
]

# Per-schema grants
schema_grants = [
  # { schema_name = "kindling", principal = "my-sp-app-id", privileges = ["USE_SCHEMA", "CREATE_TABLE", "CREATE_VOLUME", "MODIFY"] },
]

medallion_schema_grants = [
  # { schema_name = "bronze", principal = "my-sp-app-id", privileges = ["USE_SCHEMA", "SELECT"] },
]

# Per-external-location grants
external_location_grants = [
  # { location_name = "artifacts", principal = "my-sp-app-id", privileges = ["BROWSE", "READ_FILES", "WRITE_FILES"] },
]

# Per-volume grants (volumes live in catalog.kindling_schema_name)
volume_grants = [
  # { volume_name = "artifacts", principal = "my-sp-app-id", privileges = ["READ_VOLUME", "WRITE_VOLUME"] },
]

# Grants on the storage credential
storage_credential_grants = []

# -- Secret Scope ACLs -------------------------------------------------------
secret_scope_acls = [
  # { scope = "my-scope", principal = "user@example.com", permission = "MANAGE" },
]

# -- Entitlements -------------------------------------------------------------
# User-level entitlements (allow_cluster_create, workspace_access, etc.)
user_entitlements = [
  # { user_name = "user@example.com", allow_cluster_create = true, allow_instance_pool_create = true },
]

# Service principal entitlements
sp_entitlements = [
  # { application_id = "00000000-...", workspace_access = true, databricks_sql_access = true },
]
