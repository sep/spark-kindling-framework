[build-system]
requires = ["poetry-core>=1.0.0"]
build-backend = "poetry.core.masonry.api"

[tool.poetry]
name = "kindling"
version = "0.5.0"
description = "A unified framework for data apps across Fabric, Synapse, and Databricks"
authors = ["SEP Engineering <engineering@sep.com>"]
license = "MIT"
readme = "README.md"
packages = [
    {include = "kindling", from = "packages"}
]

[tool.poetry.dependencies]
python = "^3.10"
pyspark = ">=3.4.0"
delta-spark = ">=2.4.0"
pandas = ">=2.0.0"
pyarrow = ">=12.0.0"
injector = ">=0.20.1"
dynaconf = ">=3.1.0"
pyyaml = ">=6.0"
packaging = ">=23.0"
blinker = ">=1.6.0"
azure-storage-blob = ">=12.14.0"
azure-storage-file-datalake = ">=12.14.0"
azure-identity = ">=1.15.0"
azure-core = ">=1.30.0,<1.31.0"  # Pin to 1.30.x - compatible with Fabric runtime 1.30.2
azure-synapse-artifacts = "0.17.0"
databricks-sdk = ">=0.12.0"

[tool.poetry.group.dev.dependencies]
pytest = ">=7.0.0"
pytest-cov = ">=4.0.0"
pytest-json-report = ">=1.5.0"
black = ">=23.0.0"
pylint = ">=2.17.0"
mypy = ">=1.0.0"
ipython = ">=8.0.0"
jupyter = ">=1.0.0"
poethepoet = ">=0.24.0"
requests = ">=2.31.0"
azure-mgmt-storage = "^24.0.0"

[tool.poe.tasks]
# Version management
version = { script = "scripts.bump_version:main", help = "Bump version and optionally build/deploy", args = [{name = "bump_type", default = "alpha", positional = false, help = "Version bump type: alpha (default), patch, minor, major"}, {name = "platform", default = "", positional = false, help = "Platform to deploy after bump (fabric, synapse, databricks). Implies build+deploy"}, {name = "build", type = "boolean", default = false, positional = false, help = "Build wheels after version bump"}, {name = "deploy", type = "boolean", default = false, positional = false, help = "Deploy all platforms after build"}] }

# Build and deploy tasks
build = { script = "scripts.build:main" }
build-wheels = { shell = "bash scripts/build_platform_wheels.sh" }
deploy = { script = "scripts.test_runner:run_deploy", help = "Deploy wheels to Azure Storage. Use --platform and/or --release to filter", args = [{name = "platform", default = "", positional = false, help = "Platform to deploy (fabric, synapse, databricks). If not specified, deploys all platforms"}, {name = "release", default = "", positional = false, help = "Deploy from GitHub release. Use 'latest' or specific version (e.g., '0.4.0'). If not specified, deploys from local dist/"}] }
deploy-app = { script = "scripts.test_runner:run_deploy_app", help = "Deploy a data app to Azure Storage", args = [{name = "app_path", positional = false, help = "Path to app directory or .kda file"}, {name = "app_name", default = "", positional = false, help = "Name for the deployed app (defaults to directory name)"}] }
deploy-extensions = { cmd = "python scripts/deploy_extensions.py kindling-otel-azure" }
upload = { shell = "bash scripts/upload_to_storage.sh" }
upload-release = { shell = "bash scripts/upload_to_storage.sh --release" }

# Release tasks
release = { shell = "bash scripts/release.sh" }

# Development environment setup
init-azure = { shell = "source scripts/init_azure_dev.sh" }
setup-github-secrets = { shell = "bash scripts/set_github_secrets.sh" }

# Testing tasks
test = "pytest tests/ -v"
test-unit = "pytest tests/unit/ -v"
test-integration = "pytest tests/integration/ -v"
test-system = { script = "scripts.test_runner:run_system_tests", help = "Run system tests. Use --platform and/or --test to filter", args = [{name = "platform", default = "", positional = false, help = "Platform to test (fabric, synapse, databricks). If not specified, runs all platforms"}, {name = "test", default = "", positional = false, help = "Specific test name or pattern to run. If not specified, runs all tests"}] }
test-extension = { script = "scripts.test_runner:run_extension_tests", help = "Run extension tests", args = [{name = "extension", default = "azure-monitor", positional = false, help = "Extension name to test (e.g., azure-monitor)"}, {name = "platform", default = "", positional = false, help = "Platform to test (fabric, synapse, databricks). If not specified, runs all platforms"}] }
test-quick = "pytest tests/unit/ tests/integration/ -v"
test-coverage = "pytest tests/ -v --cov=kindling --cov-report=html --cov-report=term"
cleanup = { script = "scripts.test_runner:run_cleanup", help = "Clean up test resources. Use --platform to filter", args = [{name = "platform", default = "", positional = false, help = "Platform to clean (fabric, synapse, databricks). If not specified, cleans all platforms"}, {name = "skip-packages", default = false, positional = false, help = "Skip cleanup of old packages"}] }

# Code quality tasks
format = "black packages/ tests/ scripts/"
lint = "pylint packages/"
check = ["format", "lint", "test"]

[tool.black]
line-length = 100
target-version = ["py310", "py311"]

[tool.pylint.messages_control]
disable = [
    "C0111",  # missing-docstring
    "C0103",  # invalid-name
]

[tool.pylint.format]
max-line-length = 100

[tool.mypy]
python_version = "3.10"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = false

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]
addopts = [
    "--verbose",
    "--cov=kindling",
    "--cov-report=term-missing",
    "--cov-report=html:htmlcov",
]
markers = [
    "integration: Integration tests requiring Spark session but no cloud infrastructure",
    "synapse: Synapse-specific system tests (requires Azure Synapse Analytics)",
    "databricks: Databricks-specific system tests (requires Databricks workspace)",
    "fabric: Fabric-specific system tests (requires Microsoft Fabric)",
    "standalone: Standalone-specific tests (requires generic Spark or local environment)",
    "system: System tests requiring cloud infrastructure",
    "requires_azure: Tests requiring Azure credentials and SDK",
    "skip_cleanup: Skip automatic cleanup of test resources (for manual monitoring)",
]

[tool.coverage.run]
data_file = ".coverage"
